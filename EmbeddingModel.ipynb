{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e2bf86",
   "metadata": {},
   "source": [
    "## Embedding model ##\n",
    ">Floris Menninga \\\n",
    ">Datum: 8-01-2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be72d87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-24 19:46:38.535114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769280398.643686   35445 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769280398.677818   35445 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769280398.852898   35445 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769280398.852928   35445 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769280398.852932   35445 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769280398.852935   35445 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-24 19:46:38.882742: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %pip install tensorflow keras\n",
    "# #%pip install tqdm\n",
    "# %pip install tensorflow_text\n",
    "# %pip install bs4\n",
    "# %pip install joblib\n",
    "# %pip install lxml\n",
    "\n",
    "from data_parser import xml_parser\n",
    "import EmbeddingModel\n",
    "\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import lxml\n",
    "\n",
    "%load_ext tensorboard\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea16484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpu's:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-24 19:46:44.925603: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2026-01-24 19:46:44.925770: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2026-01-24 19:46:44.925782: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: FLORIS-2\n",
      "2026-01-24 19:46:44.925788: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: FLORIS-2\n",
      "2026-01-24 19:46:44.925869: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program. The library may be missing or provided via another object.\n",
      "2026-01-24 19:46:44.926010: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 580.119.2\n"
     ]
    }
   ],
   "source": [
    "os.environ['LD_LIBRARY_PATH'] = '/run/opengl-driver/lib:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "print(\"Gpu's: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f3220",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "De eerste stap is het omzetten van de text in tokens:\n",
    "In tegenstelling to methodes zoals bytepair encoding etc. worden de tokens gemaakt door de zinnen \\\n",
    "te splitten op spaties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d82f9469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hallo, dit is een testzin om het programma te testen.\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999d3e5",
   "metadata": {},
   "source": [
    "### Vocabulary maken van deze tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6de822cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'hallo,': 1, 'dit': 2, 'is': 3, 'een': 4, 'testzin': 5, 'om': 6, 'het': 7, 'programma': 8, 'te': 9, 'testen.': 10}\n"
     ]
    }
   ],
   "source": [
    "vocab, index = {}, 1 \n",
    "vocab['<pad>'] = 0\n",
    "for token in tokens:\n",
    "  if token not in vocab:\n",
    "    vocab[token] = index\n",
    "    index += 1\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf9e31",
   "metadata": {},
   "source": [
    "### Inverse vocabulary:\n",
    "Van integer index naar token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2fd28b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'hallo,', 2: 'dit', 3: 'is', 4: 'een', 5: 'testzin', 6: 'om', 7: 'het', 8: 'programma', 9: 'te', 10: 'testen.'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f79c57",
   "metadata": {},
   "source": [
    "## Vectorizeren van de zin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e953496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "test_sequence = [vocab[word] for word in tokens]\n",
    "\n",
    "print(test_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71d341",
   "metadata": {},
   "source": [
    "## Skip-gram maken:\n",
    "Het embedding model zal gemaakt worden met behulp van het Word2Vec algorithme. Verdere uitleg over hoe dit algorithme werkt komt straks maar om dit te kunnen gebruiken \n",
    "moet er eerst een Skip-gram model gemaatk worden. \n",
    "Het belangrijkste punt van een skip-gram is dat de vector representatie gebaseerd is op de ruimtelijke nabijheid van woorden in een zin. \n",
    "Als het woord \"Ketting\" altijd gevolgd zou worden door het woord \"zaag\" zal deze combinatie van woorden vaker voorkomen dan in andere combinaties.\n",
    "Een skip-gram model is een klein neural network met een inputlayer, embedding layer en output layer. \n",
    "Dit model moet een waarschijnlijkheids verdelings vector geven voor een gegeven input woord. Dat is dus de kans dat deze twee woorden samen voorkomen binnen de context lengte waarmee het model getrained is. De som van deze waarschijnlijkheids verdeling is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a9659dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      test_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0,\n",
    "      seed=0\n",
    ")\n",
    "\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf2e2e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4): (is, een)\n",
      "(1, 2): (hallo,, dit)\n",
      "(8, 9): (programma, te)\n",
      "(6, 8): (om, programma)\n",
      "(4, 3): (een, is)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3984ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9 3 0 2], shape=(4,), dtype=int64)\n",
      "['te', 'is', '<pad>', 'dit']\n"
     ]
    }
   ],
   "source": [
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bbf3fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce a dimension so you can use concatenation (in the next step).\n",
    "squeezed_context_class = tf.squeeze(context_class, 1)\n",
    "\n",
    "# Concatenate a positive context word with negative sampled words.\n",
    "context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# Label the first context word as `1` (positive) followed by `num_ns` `0`s (negative).\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "target = target_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ae17fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 3\n",
      "target_word     : is\n",
      "context_indices : [4 9 3 0 2]\n",
      "context_words   : ['een', 'te', 'is', '<pad>', 'dit']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41e89f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for `vocab_size` tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in the dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=4,\n",
    "          seed=0)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples\n",
    "    # with a positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          seed=0,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
    "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # Append each element from the training example to global lists.\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "\n",
    "  return targets, contexts, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29825b60",
   "metadata": {},
   "source": [
    "## Word2Vec:\n",
    "\n",
    "Het word2vec algorithme is een word embedding techniek in natural language processing die er voor zorgt dat woorden als vectors gerepresenteerd kunnen worden in een continue vector ruimte. \n",
    "Dit kan vervolgens gebruikt worden om relaties tussen woorden te achterhalen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fa49b",
   "metadata": {},
   "source": [
    "Hier zal de dataset ingeladen worden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b30b4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_ds = tf.data.TextLineDataset([\"/run/media/floris/FLORIS_3/Data_set/PubMed/dataset_100914.txt\"]).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n",
    "text_ds = tf.data.TextLineDataset([\"/home/floris/Documenten/Dataset/trainingsData.txt\"]).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64210d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3cbb9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder punctuatie / hoofdletters.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Aantal woorden in seq en vocabulary grootte:\n",
    "sequence_length = 1000\n",
    "vocab_size = 1000\n",
    "\n",
    "# Vectorize the layer en split en map strings tokens met TextVectorization:\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60dc5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "af43d40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', np.str_('the'), np.str_('of'), np.str_('and'), np.str_('in'), np.str_('to'), np.str_('a'), np.str_('for'), np.str_('with'), np.str_('were'), np.str_('was'), np.str_('that'), np.str_('is'), np.str_('cancer'), np.str_('by'), np.str_('as'), np.str_('cells'), np.str_('or'), np.str_('from')]\n"
     ]
    }
   ],
   "source": [
    "# Inverse vocab:\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f629d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriseer de data in text_ds:\n",
    "text_vector_ds = text_ds.batch(512).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "73b2e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "# Maak een lijst van deze gevectoriseerde data:\n",
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d04d2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seq in sequences[:5]:\n",
    "#   print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "abb1db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [04:59<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=5,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=0)\n",
    "\n",
    "\n",
    "# print(f\"targets.shape: {targets.shape}\")\n",
    "# print(f\"contexts.shape: {contexts.shape}\")\n",
    "# print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace14268",
   "metadata": {},
   "source": [
    "Gegenereerde data opslaan:\n",
    "Het duurde lang om te genereren dus sla ik het op in een .joblib bestand, dit zal ik ook voor sommige vervolg stappen doen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6ae09ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib_list = [targets, contexts, labels]\n",
    "\n",
    "# joblib.dump(joblib_list, \"targets_contexts_labels.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7df2aeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=((TensorSpec(shape=(20,), dtype=tf.int32, name=None), TensorSpec(shape=(20, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(20, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3960ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "14e7574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # context: (batch, context)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch, context, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    # dots: (batch, context)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cf1c4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975db19",
   "metadata": {},
   "source": [
    "Hier wordt het Word2Vec algorithme gebruikt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "04301a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e15cd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3e85f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1ms/step - accuracy: 0.5450 - loss: 1.1491\n",
      "Epoch 2/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.5578 - loss: 1.1176\n",
      "Epoch 3/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.5737 - loss: 1.0847\n",
      "Epoch 4/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.5874 - loss: 1.0569\n",
      "Epoch 5/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.5961 - loss: 1.0410\n",
      "Epoch 6/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6011 - loss: 1.0323\n",
      "Epoch 7/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.6043 - loss: 1.0270\n",
      "Epoch 8/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.6067 - loss: 1.0234\n",
      "Epoch 9/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.6086 - loss: 1.0207\n",
      "Epoch 10/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 1.0187\n",
      "Epoch 11/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.6113 - loss: 1.0171\n",
      "Epoch 12/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - accuracy: 0.6125 - loss: 1.0158\n",
      "Epoch 13/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.6133 - loss: 1.0147\n",
      "Epoch 14/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1ms/step - accuracy: 0.6139 - loss: 1.0138\n",
      "Epoch 15/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.6143 - loss: 1.0130\n",
      "Epoch 16/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1ms/step - accuracy: 0.6147 - loss: 1.0124\n",
      "Epoch 17/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.6153 - loss: 1.0118\n",
      "Epoch 18/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1ms/step - accuracy: 0.6158 - loss: 1.0114\n",
      "Epoch 19/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.6160 - loss: 1.0110\n",
      "Epoch 20/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - accuracy: 0.6164 - loss: 1.0106\n",
      "Epoch 21/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.6165 - loss: 1.0103\n",
      "Epoch 22/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.6169 - loss: 1.0100\n",
      "Epoch 23/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1ms/step - accuracy: 0.6172 - loss: 1.0098\n",
      "Epoch 24/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6173 - loss: 1.0096\n",
      "Epoch 25/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6174 - loss: 1.0094\n",
      "Epoch 26/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6176 - loss: 1.0093\n",
      "Epoch 27/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6178 - loss: 1.0091\n",
      "Epoch 28/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6180 - loss: 1.0090\n",
      "Epoch 29/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.6183 - loss: 1.0089\n",
      "Epoch 30/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6184 - loss: 1.0088\n",
      "Epoch 31/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.6187 - loss: 1.0087\n",
      "Epoch 32/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.6189 - loss: 1.0086\n",
      "Epoch 33/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6190 - loss: 1.0086\n",
      "Epoch 34/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6191 - loss: 1.0085\n",
      "Epoch 35/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6192 - loss: 1.0085\n",
      "Epoch 36/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.6192 - loss: 1.0084\n",
      "Epoch 37/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1ms/step - accuracy: 0.6193 - loss: 1.0084\n",
      "Epoch 38/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6194 - loss: 1.0084\n",
      "Epoch 39/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 1.0083\n",
      "Epoch 40/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 1.0083\n",
      "Epoch 41/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.6197 - loss: 1.0083\n",
      "Epoch 42/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1ms/step - accuracy: 0.6197 - loss: 1.0083\n",
      "Epoch 43/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 1.0082\n",
      "Epoch 44/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6195 - loss: 1.0082\n",
      "Epoch 45/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6195 - loss: 1.0082\n",
      "Epoch 46/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 1.0082\n",
      "Epoch 47/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6194 - loss: 1.0082\n",
      "Epoch 48/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6195 - loss: 1.0082\n",
      "Epoch 49/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 1.0083\n",
      "Epoch 50/50\n",
      "\u001b[1m26338/26338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1ms/step - accuracy: 0.6197 - loss: 1.0083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb251626ad0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=50, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46e4fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c7df0d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 vectors en metadata entries.\n"
     ]
    }
   ],
   "source": [
    "num_tokens = min(len(vocab), len(weights))\n",
    "\n",
    "with io.open('vectors.tsv', 'w', encoding='utf-8') as out_v, \\\n",
    "     io.open('metadata.tsv', 'w', encoding='utf-8') as out_m:\n",
    "\n",
    "    # Skip de padding token index 0:\n",
    "    for index in range(1, num_tokens):\n",
    "        word = vocab[index]\n",
    "        vec = weights[index]\n",
    "        \n",
    "        clean_word = word.strip()\n",
    "        \n",
    "        if not clean_word:\n",
    "            clean_word = \"[UNK_EMPTY]\"\n",
    "\n",
    "        # Vector\n",
    "        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "        \n",
    "        # Metadata\n",
    "        out_m.write(clean_word + \"\\n\")\n",
    "\n",
    "print(f\"{num_tokens - 1} vectors en metadata entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320b0e5",
   "metadata": {},
   "source": [
    "## Trainen van het model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "536b8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EmbeddingModel.EmbeddingModel()\n",
    "# model.load_dataset()\n",
    "# model.create_vocab()\n",
    "# model.vectorize()\n",
    "# model.generate_trainingdata()\n",
    "# model.word2vec()\n",
    "# model.fit()\n",
    "# model.save2file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7b532",
   "metadata": {},
   "source": [
    "## Data:\n",
    "Als trainingsdata gebruik ik 869597 Pubmed artikelen (~70GB) die ik gedownload heb van https://ftp.ncbi.nlm.nih.gov/pub/pmc/oa_bulk/oa_comm/xml/\n",
    "\n",
    "oa_comm_xml.PMC000xxxxxx.baseline.2025-06-26.tar.gz t/m oa_comm_xml.PMC004xxxxxx.baseline.2025-06-26.tar.gz\n",
    "\n",
    "Deze zijn nieuwer dan de artikelen uit 2021 die op /commons/data/NCBI/PubMed/ staan.\n",
    "\n",
    "Vervolgens moeten deze artikelen doorzocht worden op inhoud. \\\n",
    "De .xml bestanden hebben headers voor titel, abstract, body etc. deze doorzoek ik met behulp van mijn klasse: data_parser.py\n",
    "\n",
    "Het filteren op de drie keywords \"cancer\", \"melanoma\" en \"carcinoma\" duurde 9 uur en 30 minuten en reduceerde de hoeveelheid artikelen \n",
    "van 869597 naar 100914 (2.7GB).\n",
    "\n",
    "100914 Artikelen met deze zoekcriteria opgeslagen in: /run/media/floris/FLORIS_3/Data_set/PubMed/dataset_large.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ef1300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = [\"cancer\", \"melanoma\", \"carcinoma\"] # Niet hoofdlettergevoelig...\n",
    "\n",
    "trainings_data = xml_parser(\"/home/floris/Documenten/Dataset/PMC000xxxxxx\", \"/home/floris/Documenten/Dataset/trainingsData.txt\", keyword_list)\n",
    "\n",
    "# Filter de data:\n",
    "#trainings_data.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d8136",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70ea50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba0f664b",
   "metadata": {},
   "source": [
    "## Resultaten:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8b961",
   "metadata": {},
   "source": [
    "Het eerste model was met de volgende hyperparameters getrained:\n",
    "\n",
    "vocabulary grootte: 20000 \\\n",
    "context lengte: 100 \\\n",
    "window_size=5 \\\n",
    "num_ns=4 \\\n",
    "dims = 128\n",
    "\n",
    "Het model was erg overfit op de trainingsdata, de loss was bijna 0 en accuratesse bijna 1. \\\n",
    "De volgende poging zal een minder grote vocabulary krijgen en minder dimenties om beter te generaliseren i.p.v. de trainingsdata te onthouden. \n",
    "\n",
    "De onderstaande afbeelding weergeeft de loss en accuracy grafieken met Tensorboard:\n",
    "\n",
    "![](img/run_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde0f6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c775c3",
   "metadata": {},
   "source": [
    "Tweede run:\n",
    "\n",
    "Na het proberen van vele combinaties van hyperparameters lijken deze een veel beter resultaat te geven vergeleken met de vorige:\n",
    "\n",
    "vocabulary grootte: 1000 \\\n",
    "context lengte: 1000 \\\n",
    "window_size=5 \\\n",
    "num_ns=4 \\\n",
    "dims = 64\n",
    "\n",
    "![](img/run_2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Embedding_Model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
