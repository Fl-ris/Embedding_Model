{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e2bf86",
   "metadata": {},
   "source": [
    "## Embedding model ##\n",
    ">Floris Menninga \\\n",
    ">Datum: 8-01-2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be72d87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# %pip install tensorflow keras\n",
    "# #%pip install tqdm\n",
    "# %pip install tensorflow_text\n",
    "# %pip install bs4\n",
    "# %pip install joblib\n",
    "# %pip install lxml\n",
    "\n",
    "from data_parser import xml_parser\n",
    "import EmbeddingModel\n",
    "\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import lxml\n",
    "\n",
    "%load_ext tensorboard\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea16484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpu's:  0\n"
     ]
    }
   ],
   "source": [
    "os.environ['LD_LIBRARY_PATH'] = '/run/opengl-driver/lib:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "print(\"Gpu's: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f3220",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "De eerste stap is het omzetten van de text in tokens:\n",
    "In tegenstelling to methodes zoals bytepair encoding etc. worden de tokens gemaakt door de zinnen \\\n",
    "te splitten op spaties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d82f9469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hallo, dit is een testzin om het programma te testen.\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999d3e5",
   "metadata": {},
   "source": [
    "### Vocabulary maken van deze tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de822cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'hallo,': 1, 'dit': 2, 'is': 3, 'een': 4, 'testzin': 5, 'om': 6, 'het': 7, 'programma': 8, 'te': 9, 'testen.': 10}\n"
     ]
    }
   ],
   "source": [
    "vocab, index = {}, 1 \n",
    "vocab['<pad>'] = 0\n",
    "for token in tokens:\n",
    "  if token not in vocab:\n",
    "    vocab[token] = index\n",
    "    index += 1\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf9e31",
   "metadata": {},
   "source": [
    "### Inverse vocabulary:\n",
    "Van integer index naar token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fd28b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'hallo,', 2: 'dit', 3: 'is', 4: 'een', 5: 'testzin', 6: 'om', 7: 'het', 8: 'programma', 9: 'te', 10: 'testen.'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f79c57",
   "metadata": {},
   "source": [
    "## Vectorizeren van de zin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e953496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "test_sequence = [vocab[word] for word in tokens]\n",
    "\n",
    "print(test_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71d341",
   "metadata": {},
   "source": [
    "## Skip-gram maken:\n",
    "Het embedding model zal gemaakt worden met behulp van het Word2Vec algorithme. Verdere uitleg over hoe dit algorithme werkt komt straks maar om dit te kunnen gebruiken \n",
    "moet er eerst een Skip-gram model gemaatk worden. \n",
    "Het belangrijkste punt van een skip-gram is dat de vector representatie gebaseerd is op de ruimtelijke nabijheid van woorden in een zin. \n",
    "Als het woord \"Ketting\" altijd gevolgd zou worden door het woord \"zaag\" zal deze combinatie van woorden vaker voorkomen dan in andere combinaties.\n",
    "Een skip-gram model is een klein neural network met een inputlayer, embedding layer en output layer. \n",
    "Dit model moet een waarschijnlijkheids verdelings vector geven voor een gegeven input woord. Dat is dus de kans dat deze twee woorden samen voorkomen binnen de context lengte waarmee het model getrained is. De som van deze waarschijnlijkheids verdeling is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9659dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      test_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0,\n",
    "      seed=0\n",
    ")\n",
    "\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7f91b",
   "metadata": {},
   "source": [
    "Hieronder staan vijf van de gegenereerde skip-grams. \n",
    "Zoals in de bovenstaande code gedefinieerde \"window size\" bestaat elk skip-gram uit twee tokens. \n",
    "In dit geval zijn het hele woorden omdat het zo getokenizeerd is. \n",
    "Later wil ik nog proberen om andere tokenizatie technieken te gebruiken zoals byte pair encoding of wordpiece / sentencepiece.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf2e2e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4): (is, een)\n",
      "(1, 2): (hallo,, dit)\n",
      "(8, 9): (programma, te)\n",
      "(6, 8): (om, programma)\n",
      "(4, 3): (een, is)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007e49d",
   "metadata": {},
   "source": [
    "### Negative sampling\n",
    "\n",
    "De spikgrams functie retourneerd alle positieve skip-gram paren door met een sliding window van \n",
    "een gegeven grootte over de tekst te gaan. Voor training is dit echter niet genoeg, er moeten ook negatieve samples bij zitten. Deze negatieve skip-gram paren worden verkregen door willekeurige woorden uit de vocabulary te halen en deze samen te voegen. \n",
    "\n",
    "Nu zal er gebruik gemaakt worden van de functie \"tf.random.log_uniform_candidate_sampler\"\n",
    "om een aantal (num_ns) negatieve samples voor een gegeven target woord in een window te krijgen.\n",
    "Voor het trainen kan het."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3984ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1  0 10  2], shape=(4,), dtype=int64)\n",
      "['hallo,', '<pad>', 'testen.', 'dit']\n"
     ]
    }
   ],
   "source": [
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,\n",
    "    num_true=1,\n",
    "    num_sampled=num_ns,\n",
    "    unique=True,\n",
    "    range_max=vocab_size,\n",
    "    name=\"negative_sampling\"\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbf3fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_context_class = tf.squeeze(context_class, 1)\n",
    "\n",
    "context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "target = target_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ae17fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 3\n",
      "target_word     : is\n",
      "context_indices : [ 4  1  0 10  2]\n",
      "context_words   : ['een', 'hallo,', '<pad>', 'testen.', 'dit']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41e89f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5254fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(sequences, window_size, num_ns, vocab_size):\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=10)\n",
    "\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
    "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "\n",
    "  return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29825b60",
   "metadata": {},
   "source": [
    "## Word2Vec:\n",
    "\n",
    "Het word2vec algorithme is een word embedding techniek in natural language processing die er voor zorgt dat woorden als vectors gerepresenteerd kunnen worden in een continue vector ruimte. \n",
    "Dit kan vervolgens gebruikt worden om relaties tussen woorden te achterhalen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fa49b",
   "metadata": {},
   "source": [
    "Hier zal de dataset ingeladen worden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b30b4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_ds = tf.data.TextLineDataset([\"/run/media/floris/FLORIS_3/Data_set/PubMed/dataset_100914.txt\"]).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n",
    "text_ds = tf.data.TextLineDataset([\"/home/floris/Documenten/Dataset/trainingsData.txt\"]).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64210d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cbb9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder punctuatie / hoofdletters.\n",
    "def standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Aantal woorden in seq en vocabulary grootte:\n",
    "sequence_length = 200\n",
    "vocab_size = 20000\n",
    "\n",
    "# Vectorize the layer en split en map strings tokens met TextVectorization:\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60dc5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af43d40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', np.str_('the'), np.str_('of'), np.str_('and'), np.str_('in'), np.str_('to'), np.str_('a'), np.str_('for'), np.str_('with'), np.str_('were'), np.str_('was'), np.str_('that'), np.str_('is'), np.str_('cancer'), np.str_('by'), np.str_('as'), np.str_('cells'), np.str_('or'), np.str_('from')]\n"
     ]
    }
   ],
   "source": [
    "# Inverse vocab:\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f629d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriseer de data in text_ds:\n",
    "text_vector_ds = text_ds.batch(512).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73b2e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 00:03:09.125040: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Maak een lijst van deze gevectoriseerde data:\n",
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d04d2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seq in sequences[:5]:\n",
    "#   print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abb1db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6933/6933 [45:26<00:00,  2.54it/s]  \n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=5,\n",
    "    num_ns=5,\n",
    "    vocab_size=vocab_size)\n",
    "\n",
    "# print(f\"targets.shape: {targets.shape}\")\n",
    "# print(f\"contexts.shape: {contexts.shape}\")\n",
    "# print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace14268",
   "metadata": {},
   "source": [
    "Gegenereerde data opslaan:\n",
    "Het duurde lang om te genereren dus sla ik het op in een .joblib bestand, dit zal ik ook voor sommige vervolg stappen doen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae09ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib_list = [targets, contexts, labels]\n",
    "\n",
    "# joblib.dump(joblib_list, \"targets_contexts_labels.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7df2aeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=((TensorSpec(shape=(256,), dtype=tf.int32, name=None), TensorSpec(shape=(256, 6), dtype=tf.int64, name=None)), TensorSpec(shape=(256, 6), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3960ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14e7574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # context: (batch, context)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch, context, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    # dots: (batch, context)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf1c4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975db19",
   "metadata": {},
   "source": [
    "Hier wordt het Word2Vec algorithme gebruikt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04301a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 48\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e15cd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e85f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 7ms/step - accuracy: 0.5895 - loss: 1.0613\n",
      "Epoch 2/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 7ms/step - accuracy: 0.5973 - loss: 1.0306\n",
      "Epoch 3/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 7ms/step - accuracy: 0.6085 - loss: 1.0099\n",
      "Epoch 4/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 7ms/step - accuracy: 0.6189 - loss: 0.9922\n",
      "Epoch 5/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6255 - loss: 0.9817\n",
      "Epoch 6/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 7ms/step - accuracy: 0.6299 - loss: 0.9751\n",
      "Epoch 7/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 7ms/step - accuracy: 0.6331 - loss: 0.9705\n",
      "Epoch 8/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 7ms/step - accuracy: 0.6355 - loss: 0.9671\n",
      "Epoch 9/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 7ms/step - accuracy: 0.6374 - loss: 0.9644\n",
      "Epoch 10/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 7ms/step - accuracy: 0.6388 - loss: 0.9623\n",
      "Epoch 11/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6401 - loss: 0.9606\n",
      "Epoch 12/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6412 - loss: 0.9591\n",
      "Epoch 13/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6422 - loss: 0.9578\n",
      "Epoch 14/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6430 - loss: 0.9568\n",
      "Epoch 15/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6438 - loss: 0.9558\n",
      "Epoch 16/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6444 - loss: 0.9549\n",
      "Epoch 17/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6450 - loss: 0.9542\n",
      "Epoch 18/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6455 - loss: 0.9535\n",
      "Epoch 19/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6460 - loss: 0.9529\n",
      "Epoch 20/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6464 - loss: 0.9523\n",
      "Epoch 21/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6468 - loss: 0.9518\n",
      "Epoch 22/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6472 - loss: 0.9513\n",
      "Epoch 23/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6475 - loss: 0.9508\n",
      "Epoch 24/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6479 - loss: 0.9504\n",
      "Epoch 25/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6481 - loss: 0.9500\n",
      "Epoch 26/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6484 - loss: 0.9496\n",
      "Epoch 27/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6487 - loss: 0.9493\n",
      "Epoch 28/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6489 - loss: 0.9489\n",
      "Epoch 29/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6492 - loss: 0.9486\n",
      "Epoch 30/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6494 - loss: 0.9483\n",
      "Epoch 31/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6496 - loss: 0.9480\n",
      "Epoch 32/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6498 - loss: 0.9477\n",
      "Epoch 33/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6500 - loss: 0.9475\n",
      "Epoch 34/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6501 - loss: 0.9472\n",
      "Epoch 35/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6503 - loss: 0.9470\n",
      "Epoch 36/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6505 - loss: 0.9467\n",
      "Epoch 37/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6506 - loss: 0.9465\n",
      "Epoch 38/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6508 - loss: 0.9463\n",
      "Epoch 39/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6509 - loss: 0.9461\n",
      "Epoch 40/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6510 - loss: 0.9459\n",
      "Epoch 41/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6511 - loss: 0.9457\n",
      "Epoch 42/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6512 - loss: 0.9455\n",
      "Epoch 43/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6513 - loss: 0.9453\n",
      "Epoch 44/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6514 - loss: 0.9451\n",
      "Epoch 45/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7ms/step - accuracy: 0.6515 - loss: 0.9449\n",
      "Epoch 46/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6516 - loss: 0.9448\n",
      "Epoch 47/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6517 - loss: 0.9446\n",
      "Epoch 48/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7ms/step - accuracy: 0.6518 - loss: 0.9444\n",
      "Epoch 49/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7ms/step - accuracy: 0.6519 - loss: 0.9443\n",
      "Epoch 50/50\n",
      "\u001b[1m49020/49020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 7ms/step - accuracy: 0.6519 - loss: 0.9441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb2e3549e10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=50, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46e4fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f93d186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weights_vocab.joblib']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_list = [weights, vocab]\n",
    "\n",
    "joblib.dump(joblib_list, \"weights_vocab.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7df0d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999 vectors en metadata entries.\n"
     ]
    }
   ],
   "source": [
    "num_tokens = min(len(vocab), len(weights))\n",
    "\n",
    "with io.open('vectors.tsv', 'w', encoding='utf-8') as out_v, \\\n",
    "     io.open('metadata.tsv', 'w', encoding='utf-8') as out_m:\n",
    "\n",
    "    # Skip token 0\n",
    "    for index in range(1, num_tokens):\n",
    "        word = vocab[index]\n",
    "        vec = weights[index]\n",
    "        \n",
    "        clean_word = word.strip()\n",
    "        \n",
    "        if not clean_word:\n",
    "            clean_word = \"[UNK_EMPTY]\"\n",
    "\n",
    "        # Vector\n",
    "        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "        \n",
    "        # Metadata\n",
    "        out_m.write(clean_word + \"\\n\")\n",
    "\n",
    "print(f\"{num_tokens - 1} vectors en metadata entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320b0e5",
   "metadata": {},
   "source": [
    "## Trainen van het model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "536b8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EmbeddingModel.EmbeddingModel()\n",
    "# model.load_dataset()\n",
    "# model.create_vocab()\n",
    "# model.vectorize()\n",
    "# model.generate_trainingdata()\n",
    "# model.word2vec()\n",
    "# model.fit()\n",
    "# model.save2file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7b532",
   "metadata": {},
   "source": [
    "## Data:\n",
    "Als trainingsdata gebruik ik 869597 Pubmed artikelen (~70GB) die ik gedownload heb van https://ftp.ncbi.nlm.nih.gov/pub/pmc/oa_bulk/oa_comm/xml/\n",
    "\n",
    "oa_comm_xml.PMC000xxxxxx.baseline.2025-06-26.tar.gz t/m oa_comm_xml.PMC004xxxxxx.baseline.2025-06-26.tar.gz\n",
    "\n",
    "Deze zijn nieuwer dan de artikelen uit 2021 die op /commons/data/NCBI/PubMed/ staan.\n",
    "\n",
    "Vervolgens moeten deze artikelen doorzocht worden op inhoud. \\\n",
    "De .xml bestanden hebben headers voor titel, abstract, body etc. deze doorzoek ik met behulp van mijn klasse: data_parser.py\n",
    "\n",
    "Het filteren op de drie keywords \"cancer\", \"melanoma\" en \"carcinoma\" duurde 9 uur en 30 minuten en reduceerde de hoeveelheid artikelen \n",
    "van 869597 naar 100914 (2.7GB).\n",
    "\n",
    "100914 Artikelen met deze zoekcriteria opgeslagen in: /run/media/floris/FLORIS_3/Data_set/PubMed/dataset_large.txt\n",
    "\n",
    "Voor lateren trainingsruns heb ik de data_parser.py aangepast zodat hij inplaats van het hele artikel op een enkele regel zet, een alinea per regel zet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ef1300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028 XML bestanden...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3028/3028 [00:50<00:00, 59.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voltooid...\n",
      "194 Artikelen met deze zoekcriteria opgeslagen in: /home/floris/Documenten/Dataset/trainingsData.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "keyword_list = [\"cancer\", \"melanoma\", \"carcinoma\"] # Niet hoofdlettergevoelig...\n",
    "\n",
    "trainings_data = xml_parser(\"/home/floris/Documenten/Dataset/PMC000xxxxxx\", \"/home/floris/Documenten/Dataset/trainingsData.txt\", keyword_list)\n",
    "\n",
    "# Filter de data:\n",
    "trainings_data.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d8136",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70ea50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba0f664b",
   "metadata": {},
   "source": [
    "## Resultaten:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8b961",
   "metadata": {},
   "source": [
    "Het eerste model was met de volgende hyperparameters getrained:\n",
    "\n",
    "vocabulary grootte: 20000 \\\n",
    "context lengte: 100 \\\n",
    "window_size=5 \\\n",
    "num_ns=4 \\\n",
    "dims = 128\n",
    "\n",
    "Het model was erg overfit op de trainingsdata, de loss was bijna 0 en accuratesse bijna 1. \\\n",
    "De volgende poging zal een minder grote vocabulary krijgen en minder dimenties om beter te generaliseren i.p.v. de trainingsdata te onthouden. \n",
    "\n",
    "De onderstaande afbeelding weergeeft de loss en accuracy grafieken met Tensorboard:\n",
    "\n",
    "![](img/run_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde0f6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c775c3",
   "metadata": {},
   "source": [
    "### Tweede run:\n",
    "\n",
    "Na het proberen van vele combinaties van hyperparameters lijken deze een veel beter resultaat te geven vergeleken met de vorige:\n",
    "\n",
    "vocabulary grootte: 1000 \\\n",
    "context lengte: 1000 \\\n",
    "window_size=5 \\\n",
    "num_ns=4 \\\n",
    "dims = 64\n",
    "\n",
    "![](img/run_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b5341",
   "metadata": {},
   "source": [
    "### Derde run:\n",
    "\n",
    "\n",
    "vocabulary grootte: 20000 \\\n",
    "context lengte: 300 \\\n",
    "window_size=5 \\\n",
    "num_ns=5 \\\n",
    "dims = 64\n",
    "\n",
    "\n",
    "![run_3.png](img/run_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0098e",
   "metadata": {},
   "source": [
    "Deze laatste trainingsronde heb ik met een kleinere subset van de artikelen gemaakt dan de eerste. Het gefilterde .txt bestand bevatte maar 197 artikelen.\n",
    "\n",
    "Het aantal regels: `wc -l trainingData.txt` = 6934 regels \\\n",
    "Aantal woorden `wc -w trainingData.txt` = 607965 woorden \\\n",
    "\n",
    "Voor de keywords waarop ik gefilterd heb, \"cancer\", \"melanoma\" en \"carcinoma\", dit is hoeveel zinnen deze woorden bevatten: \\\n",
    "`grep -o \"cancer\" trainingsData.txt | wc -l` = 4511 \\\n",
    "`grep -o \"melanoma\" trainingsData.txt | wc -l` = 588 \\\n",
    "`grep -o \"carcinoma\" trainingsData.txt | wc -l` = 1137 \\\n",
    " \n",
    "\n",
    "### Frequentie analyse trainingstekst:\n",
    "\n",
    "`cat trainingsData.txt | tr -s ' ' '\\n' | sort | uniq -c | sort -nr | head -50` =\n",
    "\n",
    "```\n",
    "  27802 the\n",
    "  24475 of\n",
    "  17275 and\n",
    "  14315 in\n",
    "  11189 to\n",
    "   8467 a\n",
    "   6657 with\n",
    "   6243 for\n",
    "   5475 were\n",
    "   5346 was\n",
    "   4782 that\n",
    "   4563 is\n",
    "   4321 The\n",
    "   3910 by\n",
    "   3545 as\n",
    "   3086 cancer\n",
    "   2950 or\n",
    "   2854 be\n",
    "   2826 from\n",
    "   2671 are\n",
    "   2635 cells\n",
    "   2347 on\n",
    "   2341 at\n",
    "   2235 patients\n",
    "   2149 not\n",
    "   2129 cell\n",
    "   2056 tumor\n",
    "   1880 this\n",
    "   1826 have\n",
    "   1703 In\n",
    "   1675 an\n",
    "   1482 expression\n",
    "   1365 which\n",
    "   1322 been\n",
    "   1258 these\n",
    "   1203 between\n",
    "   1192 we\n",
    "   1189 may\n",
    "   1175 has\n",
    "   1112 using\n",
    "   1111 than\n",
    "   1105 study\n",
    "   1103 also\n",
    "   1094 data\n",
    "    986 breast\n",
    "    979 used\n",
    "    918 This\n",
    "    915 more\n",
    "    910 all\n",
    "    901 can\n",
    "\n",
    "```\n",
    "\n",
    "Dit bovenstaande bash statement wordt elk woord in een nieuwe regel gezet, het blijkt dus dat de \"stopwoorden\" die in normale zinnen voorkomen. Dit is voor de 50 meest frequent voorkomende woorden gedaan. \n",
    "Ik heb uit verschillende bronnen tegensprekende informatie gevonden ([Verminderen van stopwoorden](\"https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\") en [Niet verwijderen van stopwoorden](\"https://maartengr.github.io/BERTopic/getting_started/tips_and_tricks/tips_and_tricks.html\")) over het nut van het verwijderen van stopwoorden. \\\n",
    "Uiteindelijk heb ik er voor gekozen om ze niet te verwijderen omdat deze woorden toch waarschijnlijk een belangrijke rol spelen in de relaties tussen woorden in zinnen. \\\n",
    "Ook het keyword \"cancer\" waar ik op gefilderd heb komt voor in de top 50, mijn speculatie is dat het nu zo onevenredig vaak voorkomt dat het woord geassocieerd wordt met te veel andere woorden. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2de82",
   "metadata": {},
   "source": [
    "# Conclusie:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Embedding_Model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
